{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7b477c8",
   "metadata": {},
   "source": [
    "# Vectors, Vectors, Vectors\n",
    "\n",
    "As with many things in life, it all boils down to linear algebra and a few non-linear functions.\n",
    "\n",
    "Vector representations enables similarity calculations and we can think of several applications that follow from it: question answering, evaluation procedures, fetching related texts, etc. Because of this usefulness, we want to find efficient ways of 1) obtaining vector representations, 2) operating on them, and 3) storing them for later use.\n",
    "\n",
    "In this notebook, we will discuss how to obtain embeddings from OpenAI API and use a vector database to store and operate on vector representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ef1d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv ../../05_src/.secrets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18829604",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "import os\n",
    "client = OpenAI(base_url='https://k7uffyg03f.execute-api.us-east-1.amazonaws.com/prod/openai/v1', \n",
    "                api_key='any value',\n",
    "                default_headers={\"x-api-key\": os.getenv('API_GATEWAY_KEY')})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0adb5340",
   "metadata": {},
   "source": [
    "Our sample phrases cover three topics: freedom, friendship, and food."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d6017d",
   "metadata": {},
   "outputs": [],
   "source": [
    "phrases = [\n",
    "    # Good food (10)\n",
    "    \"A warm meal turns a hard day into something you can survive.\",\n",
    "    \"The best seasoning is the feeling that someone made this for you.\",\n",
    "    \"Good cooking is attention made edible.\",\n",
    "    \"A shared table is a small, daily celebration.\",\n",
    "    \"Comfort has a flavor, and it usually tastes like home.\",\n",
    "    \"Food is memory you can hold in your hands.\",\n",
    "    \"The first bite can be a doorway back to your happiest place.\",\n",
    "    \"When the soup is right, the whole world softens a little.\",\n",
    "    \"The simplest dish becomes extraordinary when it’s made with care.\",\n",
    "    \"A good meal doesn’t just feed you—it reassures you.\",\n",
    "\n",
    "    # Friendship (10)\n",
    "    \"Real friends don’t rescue you from storms; they sit beside you in the rain.\",\n",
    "    \"Friendship is the quiet agreement to keep showing up.\",\n",
    "    \"A friend is someone who makes your good news bigger and your bad news smaller.\",\n",
    "    \"You can measure trust by how safe silence feels.\",\n",
    "    \"The truest kindness is being understood without needing to perform.\",\n",
    "    \"Friendship is laughing at the same nonsense for years and never getting tired of it.\",\n",
    "    \"The best friendships feel like exhaling.\",\n",
    "    \"A friend is a mirror that reflects your worth on days you forget it.\",\n",
    "    \"Some people become home, even if you never share an address.\",\n",
    "    \"Good friends help you carry life without making you feel heavy.\",\n",
    "\n",
    "    # Community (10)\n",
    "    \"Community is strangers becoming neighbors one small favor at a time.\",\n",
    "    \"Belonging isn’t found—it’s built.\",\n",
    "    \"A community is a chorus: different voices, one song.\",\n",
    "    \"When one person is lifted, the whole street rises a little.\",\n",
    "    \"Care is the infrastructure that holds a place together.\",\n",
    "    \"A shared future starts with shared responsibility.\",\n",
    "    \"The strongest neighborhoods are stitched together by everyday generosity.\",\n",
    "    \"Community is the art of making room for one more.\",\n",
    "    \"We are safer when we are seen.\",\n",
    "    \"Together is a direction, not just a feeling.\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b773c1",
   "metadata": {},
   "source": [
    "We have 14 phrases in total:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a5f43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(phrases)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9658cb78",
   "metadata": {},
   "source": [
    "To obtain embeddings, we will use the `text-embedding-3-small` model. This model generates 1536-dimensional vectors for each input text. \n",
    "\n",
    "The documentation for the embeddings API can be found [here](https://platform.openai.com/docs/guides/embeddings)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e12b15a4",
   "metadata": {},
   "source": [
    "# A Simple Input\n",
    "\n",
    "We first start with a simple example using the first document/phrase:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b422338",
   "metadata": {},
   "outputs": [],
   "source": [
    "phrases[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7509f6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(base_url='https://k7uffyg03f.execute-api.us-east-1.amazonaws.com/prod/openai/v1', \n",
    "                api_key='any value',\n",
    "                default_headers={\"x-api-key\": os.getenv('API_GATEWAY_KEY')})\n",
    "\n",
    "response = client.embeddings.create(\n",
    "    input = phrases[0], \n",
    "    model = \"text-embedding-3-small\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9e5290",
   "metadata": {},
   "outputs": [],
   "source": [
    "response.data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9515ac",
   "metadata": {},
   "source": [
    "# Loop through Simple Inputs\n",
    "\n",
    "We will now try the example found in the [API documentation](https://platform.openai.com/docs/guides/embeddings/embeddings#obtaining-the-embeddings), which simply loops through the documents, calling the API each time. The function below first performs a simple cleanup (removes line breaks), then requests the embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2f6611",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(text, model=\"text-embedding-3-small\"):\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "    return client.embeddings.create(input=[text], model=model).data[0].embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4045b3c3",
   "metadata": {},
   "source": [
    "Using Python's list comprehension syntax, we can run the function for each of our example phrases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a094372",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = [get_embedding(doc) for doc in phrases]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0e8610",
   "metadata": {},
   "source": [
    "The statement above is roughly equivalent to:\n",
    "\n",
    "```python\n",
    "embeddings = []\n",
    "for doc in phrases:\n",
    "    doc_emb = get_embedding(doc)\n",
    "    embeddings.append(doc_emb)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f2b331",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b8efcd",
   "metadata": {},
   "source": [
    "# Sending Lists of Inputs to the API\n",
    "\n",
    "We can also send a collection of inputs to the API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb8d086",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(base_url='https://k7uffyg03f.execute-api.us-east-1.amazonaws.com/prod/openai/v1', \n",
    "                api_key='any value',\n",
    "                default_headers={\"x-api-key\": os.getenv('API_GATEWAY_KEY')})\n",
    "\n",
    "response = client.embeddings.create(\n",
    "    input = phrases, \n",
    "    model = \"text-embedding-3-small\"\n",
    ")\n",
    "response.data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "029bf18b",
   "metadata": {},
   "source": [
    "# Vector DB\n",
    "\n",
    "We can use a specialized database to store our embeddings, relate them to documents, and efficiently perform computations like cosine similarity.\n",
    "\n",
    "![](img/02_chroma.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc994ef1",
   "metadata": {},
   "source": [
    "The document database that we will use for our experiments is Chroma DB, a simple implementation of Vector DB that is commonly used for prototyping. \n",
    "\n",
    "A few useful references are: \n",
    "- [ChromaDB Documentation](https://docs.trychroma.com/docs/overview/introduction).\n",
    "- [ChromaDB Cookbook](https://cookbook.chromadb.dev/running/running-chroma/#chroma-cli).\n",
    "\n",
    "Chroma can be run locally in memory, locally using file persistence, or using a Docker container."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ddc9e1",
   "metadata": {},
   "source": [
    "## Running Chroma Locally in Memory\n",
    "\n",
    "The simplest implementation is to run Chroma DB in memory without persistence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6efc956f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "\n",
    "chroma_client = chromadb.Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49cefa71",
   "metadata": {},
   "source": [
    "First, create a collection. A collection is a container that groups documents together. A collection would be equivalent to a table which groups togher records in a relational database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807e9c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = chroma_client.create_collection(name = \"nice_phrases\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc83a87f",
   "metadata": {},
   "source": [
    "Then, add documents to our collection. Each document will contain:\n",
    "\n",
    "1. An identifier.\n",
    "2. The phrase.\n",
    "3. The embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ec446d",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = [item.embedding for item in response.data]\n",
    "ids = [f\"id{i}\" for i in range(len(phrases))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adabc3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection.add(embeddings = embeddings, \n",
    "               documents = phrases, \n",
    "               ids = ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d8ff17",
   "metadata": {},
   "source": [
    "Now, we can use Chroma DB's [`query`](https://docs.trychroma.com/docs/querying-collections/query-and-get) method to perform a query using similarity search. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c3b580",
   "metadata": {},
   "source": [
    "## Performing a Search Using Custom Embeddings\n",
    "\n",
    "We could use a function such as the one below to provide our own embeddings of the query text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcfeae28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_chromadb(query, top_n = 2):\n",
    "    query_embedding = get_embedding(query)\n",
    "    results = collection.query(query_embeddings = [query_embedding], n_results = top_n)\n",
    "    return [(id, score, text) for id, score, text in zip(results['ids'][0], results['distances'][0], results['documents'][0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23afe9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is good food?\"\n",
    "\n",
    "query_chromadb(query, top_n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3689b80",
   "metadata": {},
   "source": [
    "## Performing a Search Using Embedding Function\n",
    "\n",
    "Alternatively, we can define the embedding function at the moment in which we create the collection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f51ea640",
   "metadata": {},
   "source": [
    "If needed, list and remove any collection as you require:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85dd1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_client.list_collections()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8569b73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_client.delete_collection(\"nice_phrases\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74ad5c5",
   "metadata": {},
   "source": [
    "We can now re-use the collection name using an OpenAI embedding function. Notice that we pass the `api_key` parameter explicitly, as the environment variable name that holds the API key for Chroma DB and for the OpenAI library are different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ddaadb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from chromadb.utils.embedding_functions import OpenAIEmbeddingFunction\n",
    "\n",
    "collection = chroma_client.create_collection(\n",
    "    name = \"nice_phrases\",\n",
    "    embedding_function = OpenAIEmbeddingFunction(\n",
    "        api_key = \"any value\",\n",
    "        model_name=\"text-embedding-3-small\",\n",
    "        api_base='https://k7uffyg03f.execute-api.us-east-1.amazonaws.com/prod/openai/v1',\n",
    "        default_headers={\"x-api-key\": os.getenv('API_GATEWAY_KEY')}\n",
    "))\n",
    "collection.add(embeddings = embeddings, \n",
    "               documents = phrases, \n",
    "               ids = ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f8a606",
   "metadata": {},
   "source": [
    "With the embedding function, we can now perform the query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56edaed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection.query(\n",
    "    query_texts = [\"What is a friend?\", \"What is good food?\"], \n",
    "    n_results = 2\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deploying-ai-env (3.11.13)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
