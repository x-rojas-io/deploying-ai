{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40ef0627",
   "metadata": {},
   "source": [
    "# Embeddings via API\n",
    "\n",
    "In this notebook, we demonstrate how to obtain embeddings using OpenAI's API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d340a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv ../../05_src/.secrets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6890865",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [\n",
    "    \"The machine learning model predicts customer behavior based on historical data.\",\n",
    "    \"The machine learning model predicts user behavior using historical data.\",\n",
    "    \"A machine learning model predicts customer behavior from past data.\",\n",
    "    \"The predictive model uses historical customer data to forecast behavior.\",\n",
    "    \"Customer behavior is predicted by a data-driven machine learning system.\",\n",
    "    \"Historical data is analyzed to understand how customers behave.\",\n",
    "    \"A data science model analyzes past information to make predictions.\",\n",
    "    \"Business analysts study customer trends to support decision making.\",\n",
    "    \"Statistical techniques are used to interpret large datasets.\",\n",
    "    \"The weather forecast was inaccurate due to missing satellite data.\",\n",
    "    \"A novel explores human relationships in a small coastal town.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76a07d1",
   "metadata": {},
   "source": [
    "OpenAI's text embeddings are available through the embeddings API. A key reference is the [Embeddings API documentation](https://platform.openai.com/docs/guides/embeddings).\n",
    "\n",
    "There are three models that we can choose from, depending on [the size of the hidden representation, latency, and cost](https://platform.openai.com/docs/guides/embeddings#embedding-models):\n",
    "\n",
    "+ `text-embedding-3-small`\n",
    "+ `text-embedding-3-large`\n",
    "+ `text-embedding-ada-002`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ebd77ae",
   "metadata": {},
   "source": [
    "A simple implementation would call the embeddings API for each phrase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3c2f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from openai import OpenAI\n",
    "import os\n",
    "client = OpenAI(base_url='https://k7uffyg03f.execute-api.us-east-1.amazonaws.com/prod/openai/v1', \n",
    "                api_key='any value',\n",
    "                default_headers={\"x-api-key\": os.getenv('API_GATEWAY_KEY')})\n",
    "\n",
    "def get_embedding(text, model=\"text-embedding-3-small\"):\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "    return client.embeddings.create(input=text, model=model).data[0].embedding\n",
    "\n",
    "embeddings = [get_embedding(doc) for doc in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26eb1056",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "embeddings_array = np.array(embeddings)\n",
    "embeddings_array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6a6038",
   "metadata": {},
   "source": [
    "## A Note on Similarity\n",
    "\n",
    "One important characteristic of embeddings is that they can be used to measure the relatedness of text strings. To see this, we can plot a reduced forms of the embeddings using Principal Components Analysis (PCA)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f2fa30",
   "metadata": {},
   "source": [
    "Similarity between two texts can be understood in two ways:\n",
    "\n",
    "+ Lexical similarity refers to similarity of the choice of words. For example, \"cats are fun\" and \"cats are furry\" are similar in that they have two words in common.\n",
    "+ Semantical similarity refers to similarity in the words meaning. For example, \"the bottle is empty\" and \"there is nothing in the bottle\" are similar in meaning, but the phrases do not have many words in common.\n",
    "\n",
    "Using count or tf-idf tokenization, we can calculate lexical similarity; using embeddings, we can compute (model-dependent) lexical similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775395af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components = 2)\n",
    "reduced_embeddings = pca.fit_transform(embeddings_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0203b680",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from adjustText import adjust_text\n",
    "\n",
    "# Sample data\n",
    "df = pd.DataFrame(reduced_embeddings, columns=[\"x\", \"y\"]).assign(label = documents)\n",
    "\n",
    "# Create the scatter plot\n",
    "fig, ax = plt.subplots()\n",
    "sns.scatterplot(x='x', y='y', data=df, ax=ax)\n",
    "\n",
    "# Add labels\n",
    "texts = []\n",
    "for i, row in df.iterrows():\n",
    "    texts.append(ax.text(row['x'], row['y'], row['label'], fontsize=6))\n",
    "\n",
    "# Adjust text positions to avoid overlap\n",
    "adjust_text(texts, arrowprops=dict(arrowstyle='-', color='black', lw=0.5))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83d\udca1 Frequently Asked Questions (FAQ)\n",
    "\n",
    "**Q: Batching request?**\n",
    "A: When processing millions of documents, sending them one by one is slow. The Embeddings API allows you to send a list of strings (a batch) in a single HTTP request. This drastically reduces network latency.\n",
    "\n",
    "**Q: Rate Limits?**\n",
    "A: APIs have limits (e.g., 5000 requests per minute). If you exceed them, you get a `429 Too Many Requests` error. You must implement \"backoff and retry\" logic to handle this.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deploying-ai-env (3.11.13)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}