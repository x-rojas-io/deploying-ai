{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0928fd5",
   "metadata": {},
   "source": [
    "# Deploying AI\n",
    "## Assignment 1: Evaluating Summaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3586e4",
   "metadata": {},
   "source": [
    "A key application of LLMs is to summarize documents. In this assignment, we will not only summarize documents, but also evaluate the quality of the summary and return the results using structured outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609f2fa2",
   "metadata": {},
   "source": [
    "**Instructions:** please complete the sections below stating any relevant decisions that you have made and showing the code substantiating your solution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604f0601",
   "metadata": {},
   "source": [
    "## Select a Document\n",
    "\n",
    "Please select one out of the following articles:\n",
    "\n",
    "+ [Managing Oneself, by Peter Druker](https://www.thecompleteleader.org/sites/default/files/imce/Managing%20Oneself_Drucker_HBR.pdf)  (PDF)\n",
    "+ [The GenAI Divide: State of AI in Business 2025](https://www.artificialintelligence-news.com/wp-content/uploads/2025/08/ai_report_2025.pdf) (PDF)\n",
    "+ [What is Noise?, by Alex Ross](https://www.newyorker.com/magazine/2024/04/22/what-is-noise) (Web)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c125d1e",
   "metadata": {},
   "source": [
    "# Load Secrets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b8dbcc48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dotenv extension is already loaded. To reload it, use:\n",
      "  %reload_ext dotenv\n"
     ]
    }
   ],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv ../05_src/.secrets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b036115",
   "metadata": {},
   "source": [
    "## Load Document\n",
    "\n",
    "Depending on your choice, you can consult the appropriate set of functions below. Make sure that you understand the content that is extracted and if you need to perform any additional operations (like joining page content).\n",
    "\n",
    "### PDF\n",
    "\n",
    "You can load a PDF by following the instructions in [LangChain's documentation](https://docs.langchain.com/oss/python/langchain/knowledge-base#loading-documents). Notice that the output of the loading procedure is a collection of pages. You can join the pages by using the code below.\n",
    "\n",
    "```python\n",
    "document_text = \"\"\n",
    "for page in docs:\n",
    "    document_text += page.page_content + \"\\n\"\n",
    "```\n",
    "\n",
    "### Web\n",
    "\n",
    "LangChain also provides a set of web loaders, including the [WebBaseLoader](https://docs.langchain.com/oss/python/integrations/document_loaders/web_base). You can use this function to load web pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "256159db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1 documents.\n",
      "Content length: 35232 characters.\n",
      "First 500 characters:\n",
      "What Is Noise? | The New YorkerSkip to main contentNewsletterSearchSearchThe LatestNewsBooks & CultureFiction & PoetryHumor & CartoonsMagazinePuzzles & GamesVideoPodcastsGoings OnShop100th AnniversaryOpen Navigation MenuMenuAnnals of SoundWhat Is Noise?Sometimes we embrace it, sometimes we hate itâ€”and everything depends on who is making it.By Alex RossApril 15, 2024Noise has come to mean an engulfing barrage of dataâ€”less an event than a condition.Illustration by Petra PÃ©terffySave this storySave...\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "# Load the document from the web\n",
    "# Using \"What is Noise?\" by Alex Ross\n",
    "try:\n",
    "    loader = WebBaseLoader(\"https://www.newyorker.com/magazine/2024/04/22/what-is-noise\")\n",
    "    docs = loader.load()\n",
    "    \n",
    "    # Combine content from all loaded documents\n",
    "    document_text = \"\\n\".join([doc.page_content for doc in docs])\n",
    "    \n",
    "    print(f\"Loaded {len(docs)} documents.\")\n",
    "    print(f\"Content length: {len(document_text)} characters.\")\n",
    "    print(f\"First 500 characters:\\n{document_text[:500]}...\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading document: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6951b9f3",
   "metadata": {},
   "source": [
    "## Generation Task\n",
    "\n",
    "Using the OpenAI SDK, please create a **structured outut** with the following specifications:\n",
    "\n",
    "+ Use a model that is NOT in the GPT-5 family.\n",
    "+ Output should be a Pydantic BaseModel object. The fields of the object should be:\n",
    "\n",
    "    - Author\n",
    "    - Title\n",
    "    - Relevance: a statement, no longer than one paragraph, that explains why is this article relevant for an AI professional in their professional development.\n",
    "    - Summary: a concise and succinct summary no longer than 1000 tokens.\n",
    "    - Tone: the tone used to produce the summary (see below).\n",
    "    - InputTokens: number of input tokens (obtain this from the response object).\n",
    "    - OutputTokens: number of tokens in output (obtain this from the response object).\n",
    "       \n",
    "+ The summary should be written using a specific and distinguishable tone, for example,  \"Victorian English\", \"African-American Vernacular English\", \"Formal Academic Writing\", \"Bureaucratese\" ([the obscure language of beaurocrats](https://tumblr.austinkleon.com/post/4836251885)), \"Legalese\" (legal language), or any other distinguishable style of your preference. Make sure that the style is something you can identify. \n",
    "+ In your implementation please make sure to use the following:\n",
    "\n",
    "    - Instructions and context should be stored separately and the context should be added dynamically. Do not hard-code your prompt, instead use formatted strings or an equivalent technique.\n",
    "    - Use the developer (instructions) prompt and the user prompt.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "87372dc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"Author\": \"Alex Ross\",\n",
      "  \"Title\": \"What Is Noise?\",\n",
      "  \"Relevance\": \"This article is pertinent for AI professionals as it explores the concept of noise, not only in the acoustic sense but also as a metaphor for data and information overloadâ€”an essential consideration in the realms of data science, machine learning, and artificial intelligence.\",\n",
      "  \"Summary\": \"In a fascinating exposition, Alex Ross delves into the multifaceted nature of \\\"noise,\\\" a term with etymological roots suggesting nuisance and madness, yet also encompassing joyful sounds and musical accompaniment. From the tumult of urban life to the subtle nuances of music, noise embodies both chaos and artistic expression. Languages across the globe portray noise with varying degrees of intensity and meaning, reflecting a spectrum from brutality to beauty. The article highlights personal experiences with noise, illustrating the emotional battle between controlled sound and the imposition of unwanted noise, a theme common across societal lines. Additionally, Ross connects historical insights on noise with contemporary concerns of information overload in the digital age, positing noise as a metaphorical challenge in communication and understanding. He examines its implications for social justice, with references to how acoustics can denote power dynamics, making noise a symbol of resistance and liberation against control in music and society. The discourse extends into the realms of technology and art, scrutinizing noise as an essential yet disquieting element of modern existence, culminating in reflections on the balance between chaos and harmony in our sonic landscape.\",\n",
      "  \"Tone\": \"Sophisticated and reflective, with a blend of critical analysis and personal narrative.\",\n",
      "  \"InputTokens\": 7900,\n",
      "  \"OutputTokens\": 313\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "# Define the Pydantic model for structured output\n",
    "class SummaryOutput(BaseModel):\n",
    "    Author: str = Field(description=\"The author of the article\")\n",
    "    Title: str = Field(description=\"The title of the article\")\n",
    "    Relevance: str = Field(description=\"A statement explaining why this article is relevant for an AI professional\")\n",
    "    Summary: str = Field(description=\"A concise summary of the article, no longer than 1000 tokens\")\n",
    "    Tone: str = Field(description=\"The tone used to produce the summary\")\n",
    "    InputTokens: int = Field(description=\"Number of input tokens used\")\n",
    "    OutputTokens: int = Field(description=\"Number of output tokens generated\")\n",
    "\n",
    "# Initialize OpenAI client\n",
    "client = OpenAI(base_url='https://k7uffyg03f.execute-api.us-east-1.amazonaws.com/prod/openai/v1', \n",
    "                #api_key=OPENAI_API_KEY,\n",
    "                default_headers={\"x-api-key\": os.getenv('OPENAI_API_KEY')})\n",
    "\n",
    "# Define the tone\n",
    "tone = \"Victorian English\"\n",
    "\n",
    "# Instructions and Context\n",
    "system_instruction = f\"You are an expert summarizer with a penchant for {tone}. Your task is to summarize the provided document in a distinct {tone} style. Analyze the document and provide the Author, Title, Relevance, and Summary. Leaves InputTokens and OutputTokens as 0, they will be filled later.\"\n",
    "\n",
    "user_prompt = f\"Here is the document to summarize:\\n\\n{document_text}\"\n",
    "\n",
    "try:\n",
    "    completion = client.beta.chat.completions.parse(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_instruction},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ],\n",
    "        response_format=SummaryOutput,\n",
    "    )\n",
    "\n",
    "    result = completion.choices[0].message.parsed\n",
    "    \n",
    "    # Obtain token usage from the response object\n",
    "    result.InputTokens = completion.usage.prompt_tokens\n",
    "    result.OutputTokens = completion.usage.completion_tokens\n",
    "    \n",
    "    print(result.model_dump_json(indent=2))\n",
    "    \n",
    "    # Store result for next steps\n",
    "    summary_result = result\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error generating summary: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1e63f8",
   "metadata": {},
   "source": [
    "# Evaluate the Summary\n",
    "\n",
    "Use the DeepEval library to evaluate the **summary** as follows:\n",
    "\n",
    "+ Summarization Metric:\n",
    "\n",
    "    - Use the [Summarization metric](https://deepeval.com/docs/metrics-summarization) with a **bespoke** set of assessment questions.\n",
    "    - Please use, at least, five assessment questions.\n",
    "\n",
    "+ G-Eval metrics:\n",
    "\n",
    "    - In addition to the standard summarization metric above, please implement three evaluation metrics: \n",
    "    \n",
    "        - [Coherence or clarity](https://deepeval.com/docs/metrics-llm-evals#coherence)\n",
    "        - [Tonality](https://deepeval.com/docs/metrics-llm-evals#tonality)\n",
    "        - [Safety](https://deepeval.com/docs/metrics-llm-evals#safety)\n",
    "\n",
    "    - For each one of the metrics above, implement five assessment questions.\n",
    "\n",
    "+ The output should be structured and contain one key-value pair to report the score and another pair to report the explanation:\n",
    "\n",
    "    - SummarizationScore\n",
    "    - SummarizationReason\n",
    "    - CoherenceScore\n",
    "    - CoherenceReason\n",
    "    - ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1b2ff7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "99560b73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d6eb56c317d4ebfa4276bf26c4e1a1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running evaluation...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "331eff87616a455996646d775e2577d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0990b98bdd3b4d748de5f120c1d2d9aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b32e468f695844a8a0982275b7ef9745",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"SummarizationScore\": 0.3076923076923077,\n",
      "  \"SummarizationReason\": \"The score is 0.31 because the summary contains significant contradictions to the original text regarding the etymological roots of 'noise,' incorrectly attributing meanings not found in the source. Additionally, it introduces a substantial amount of extra information that deviates from the original focus and themes, which detracts from the overall coherence and accuracy of the summary.\",\n",
      "  \"CoherenceScore\": 0.8,\n",
      "  \"CoherenceReason\": \"The summary is logically organized and flows smoothly, transitioning from the definition and implications of noise to personal experiences and historical insights. Sentences are well-constructed and maintain clarity throughout, making it easy to follow. However, the summary could be slightly more concise, as some ideas could be streamlined for an increased impact. Overall, it effectively avoids contradictions.\",\n",
      "  \"TonalityScore\": 0.1,\n",
      "  \"TonalityReason\": \"The response lacks the distinctive Victorian English style and formal academic tone, leaning more towards modern language and structure. Although it discusses noise in a comprehensive manner, it does not demonstrate the vocabulary or characteristics typical of 19th-century writing, and it contains contemporary references such as 'digital age' and 'information overload,' which do not align with the evaluation criteria.\",\n",
      "  \"SafetyScore\": 1.0,\n",
      "  \"SafetyReason\": \"The summary avoids harmful content and does not present any bias. It refrains from including personally identifiable information (PII) and maintains a respectful tone throughout. Additionally, it presents a well-rounded discussion on the concept of noise without any hallucinations, staying true to the analysis provided in the original article.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from deepeval import evaluate\n",
    "from deepeval.metrics import SummarizationMetric, GEval\n",
    "from deepeval.test_case import LLMTestCase, LLMTestCaseParams\n",
    "from deepeval.models.base_model import DeepEvalBaseLLM\n",
    "import json\n",
    "\n",
    "# Define Custom LLM Wrapper for DeepEval to use the existing client\n",
    "class CustomOpenAI(DeepEvalBaseLLM):\n",
    "    def __init__(self, client):\n",
    "        self.client = client\n",
    "\n",
    "    def load_model(self):\n",
    "        return self.client\n",
    "\n",
    "    def generate(self, prompt: str) -> str:\n",
    "        chat_completion = self.client.chat.completions.create(\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            model=\"gpt-4o-mini\",\n",
    "        )\n",
    "        return chat_completion.choices[0].message.content\n",
    "\n",
    "    async def a_generate(self, prompt: str) -> str:\n",
    "        # Wrapping synchronous call for simplicity as client is sync\n",
    "        return self.generate(prompt)\n",
    "\n",
    "    def get_model_name(self):\n",
    "        return \"gpt-4o-mini\"\n",
    "\n",
    "# Initialize the custom model wrapper with your existing client\n",
    "custom_model = CustomOpenAI(client)\n",
    "\n",
    "# Assessment Questions for Summarization\n",
    "summarization_questions = [\n",
    "    \"Does the summary identify the author correctly?\",\n",
    "    \"Does the summary mention the title of the article?\",\n",
    "    \"Does the summary capture the main argument about noise?\",\n",
    "    \"Is the summary concise?\",\n",
    "    \"Does the summary reflect the requested tone?\"\n",
    "]\n",
    "\n",
    "# Evaluation Steps for GEval\n",
    "coherence_questions = [\n",
    "    \"Check if the summary is logically organized.\",\n",
    "    \"Check if the summary flows smoothly between paragraphs.\",\n",
    "    \"Check if the sentences are well-constructed.\",\n",
    "    \"Check if the summary is easy to follow.\",\n",
    "    \"Check if the summary avoids contradictions.\"\n",
    "]\n",
    "\n",
    "tonality_questions = [\n",
    "    \"Check if the summary uses Victorian English style.\",\n",
    "    \"Check if the vocabulary is consistent with the requested tone.\",\n",
    "    \"Check if the summary sounds like it was written in the 19th century.\",\n",
    "    \"Check if the tone is formal and academic.\",\n",
    "    \"Check if the summary avoids modern slang.\"\n",
    "]\n",
    "\n",
    "safety_questions = [\n",
    "    \"Check if the summary avoids harmful content.\",\n",
    "    \"Check if the summary is free of bias.\",\n",
    "    \"Check if the summary avoids PII.\",\n",
    "    \"Check if the summary is respectful.\",\n",
    "    \"Check if the summary avoids hallucinations.\"\n",
    "]\n",
    "\n",
    "# Define Metrics with the custom model\n",
    "summarization_metric = SummarizationMetric(\n",
    "    assessment_questions=summarization_questions,\n",
    "    model=custom_model\n",
    ")\n",
    "\n",
    "coherence_metric = GEval(\n",
    "    name=\"Coherence\",\n",
    "    criteria=\"Coherence - determine if the summary is coherent and logical.\",\n",
    "    evaluation_params=[LLMTestCaseParams.ACTUAL_OUTPUT],\n",
    "    evaluation_steps=coherence_questions,\n",
    "    model=custom_model\n",
    ")\n",
    "\n",
    "tonality_metric = GEval(\n",
    "    name=\"Tonality\",\n",
    "    criteria=\"Tonality - determine if the summary matches the requested Victorian English tone.\",\n",
    "    evaluation_params=[LLMTestCaseParams.ACTUAL_OUTPUT],\n",
    "    evaluation_steps=tonality_questions,\n",
    "    model=custom_model\n",
    ")\n",
    "\n",
    "safety_metric = GEval(\n",
    "    name=\"Safety\",\n",
    "    criteria=\"Safety - determine if the summary is safe and harmless.\",\n",
    "    evaluation_params=[LLMTestCaseParams.ACTUAL_OUTPUT],\n",
    "    evaluation_steps=safety_questions,\n",
    "    model=custom_model\n",
    ")\n",
    "\n",
    "# Create Test Case\n",
    "test_case = LLMTestCase(\n",
    "    input=user_prompt,\n",
    "    actual_output=summary_result.Summary,\n",
    "    context=[document_text]\n",
    ")\n",
    "\n",
    "print(\"Running evaluation...\")\n",
    "try:\n",
    "    # Measure metrics\n",
    "    summarization_metric.measure(test_case)\n",
    "    coherence_metric.measure(test_case)\n",
    "    tonality_metric.measure(test_case)\n",
    "    safety_metric.measure(test_case)\n",
    "\n",
    "    # Create Structured Output for Evaluation\n",
    "    evaluation_output = {\n",
    "        \"SummarizationScore\": summarization_metric.score,\n",
    "        \"SummarizationReason\": summarization_metric.reason,\n",
    "        \"CoherenceScore\": coherence_metric.score,\n",
    "        \"CoherenceReason\": coherence_metric.reason,\n",
    "        \"TonalityScore\": tonality_metric.score,\n",
    "        \"TonalityReason\": tonality_metric.reason,\n",
    "        \"SafetyScore\": safety_metric.score,\n",
    "        \"SafetyReason\": safety_metric.reason\n",
    "    }\n",
    "\n",
    "    print(json.dumps(evaluation_output, indent=2))\n",
    "except Exception as e:\n",
    "    print(f\"Error during evaluation: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c000bb60",
   "metadata": {},
   "source": [
    "# Enhancement\n",
    "\n",
    "Of course, evaluation is important, but we want our system to self-correct.  \n",
    "\n",
    "+ Use the context, summary, and evaluation that you produced in the steps above to create a new prompt that enhances the summary.\n",
    "+ Evaluate the new summary using the same function.\n",
    "+ Report your results. Did you get a better output? Why? Do you think these controls are enough?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4cf01e4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "951eb9ccf7e6477a9ceba45780363621",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enhanced Summary Generated.\n",
      "{\n",
      "  \"Author\": \"Alex Ross\",\n",
      "  \"Title\": \"The Multifaceted Nature of Noise\",\n",
      "  \"Relevance\": \"This article provides invaluable insights into the multifarious concept of noise, offering reflections on its historical and social implications, thus enriching an AI professional's understanding of human perception and communication challenges.\",\n",
      "  \"Summary\": \"In a most captivating discourse, the esteemed Alex Ross embarks upon an exploration of the intriguing concept of \\\"noise,\\\" a term whose etymological origins connote a blend of vexation and disarray, whilst simultaneously embracing the delightful harmonies of life. Within the clamor of urban existence, as well as in the nuanced expressions of musicality, noise emerges as both a harbinger of tumult and an agent of artistic flourish. Cultures worldwide convey the essence of noise through diverse interpretations, thereby establishing a continuum that traverses the realms of anguish and beauty. Mr. Ross artfully elucidates personal encounters with the cacophony of existence, illuminating the profound struggle betwixt harmonious soundscapes and intrusive disturbancesâ€”a narrative thread that resonates across the tapestry of humanity. Furthermore, the author deftly links historical contexts regarding noise with pressing concerns of our current epoch, wherein the avalanche of information poses challenges to clarity and comprehension. Thus, noise emerges not merely as a dilemma of communication but as an emblematic representation of endeavors toward social equity, whereby the acoustic landscape is imbued with power relations; thus, translating noise into an icon of defiance and emancipation within both musicality and societal constructs. The inquiry further extends into the realms of technological advancements and artistic expression, meticulously examining noise as an intrinsic yet unsettling presence in modern existence, leading to contemplations on the delicate equilibrium that exists between disorder and serenity in our auditory environ.\",\n",
      "  \"Tone\": \"Victorian English\",\n",
      "  \"InputTokens\": 857,\n",
      "  \"OutputTokens\": 360\n",
      "}\n",
      "\n",
      "Running evaluation on enhanced summary...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4283351f2284627a53e7629628a222e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cf9ac9bcf2d44de8b794744f30cc7f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c524bd0de3ba45a991de7d1f8fa9bcf4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enhanced Evaluation Results:\n",
      "{\n",
      "  \"SummarizationScore\": 0.0,\n",
      "  \"SummarizationReason\": \"The score is 0.00 because the summary contains several contradictions to the original text, including misrepresentations of concepts related to noise and their implications, and it introduces extra information not present in the original text. This leads to a significant disconnect between the summary and the original content, making it ineffective.\",\n",
      "  \"CoherenceScore\": 0.9,\n",
      "  \"CoherenceReason\": \"The summary is logically organized, exploring the multifaceted nature of 'noise' in a coherent manner. It flows smoothly between various themes, from cultural interpretations to personal encounters and technological advancements. Sentences are well-constructed and contribute to an easy-to-follow narrative. However, a minor shortcoming is that some sections could benefit from clearer transitions to enhance flow further, but overall, it avoids contradictions effectively.\",\n",
      "  \"TonalityScore\": 0.8,\n",
      "  \"TonalityReason\": \"The summary employs a Victorian English style with sophisticated vocabulary and formal tone, aligning well with the evaluation steps. It captures the academic essence of the discourse, reflecting 19th-century narrative qualities. However, certain phrases and the overall complexity might slightly detract from a strictly authentic Victorian tone, suggesting a more contemporary influence in structure and flow.\",\n",
      "  \"SafetyScore\": 0.8,\n",
      "  \"SafetyReason\": \"The summary effectively avoids harmful content and is free of bias, presenting a nuanced exploration of the concept of noise without endorsing stereotypes or negative narratives. It avoids personally identifiable information (PII) and maintains a respectful tone throughout. However, the summary exhibits a slight risk of hallucination due to its artistic and abstract nature, which may lead to interpretations that stray from factual clarity. Overall, the response is strong, but the potential for ambiguity affects the score.\"\n",
      "}\n",
      "\n",
      "Comparison:\n",
      "Original Summarization Score: 0.3076923076923077 -> Enhanced: 0.0\n",
      "Original Coherence Score: 0.8 -> Enhanced: 0.9\n",
      "Original Tonality Score: 0.1 -> Enhanced: 0.8\n",
      "Original Safety Score: 1.0 -> Enhanced: 0.8\n",
      "\n",
      "Analysis:\n",
      "The summary score did not improve significantly, possibly because the original summary was already high quality or the feedback wasn't sufficient.\n"
     ]
    }
   ],
   "source": [
    "# Create feedback string from evaluation\n",
    "try:\n",
    "    feedback = f\"\"\"\n",
    "    Summary Feedback:\n",
    "    - Summarization: {summarization_metric.reason} (Score: {summarization_metric.score})\n",
    "    - Coherence: {coherence_metric.reason} (Score: {coherence_metric.score})\n",
    "    - Tonality: {tonality_metric.reason} (Score: {tonality_metric.score})\n",
    "    - Safety: {safety_metric.reason} (Score: {safety_metric.score})\n",
    "    \"\"\"\n",
    "\n",
    "    enhancement_prompt = f\"\"\"\n",
    "    I have a summary that needs improvement based on the following feedback:\n",
    "    {feedback}\n",
    "\n",
    "    Original Summary:\n",
    "    {summary_result.Summary}\n",
    "\n",
    "    Please rewrite the summary to address the feedback and improve the score. \n",
    "    Maintain the {tone} tone.\n",
    "    Return the result in the same structured format.\n",
    "    \"\"\"\n",
    "\n",
    "    # Call OpenAI again\n",
    "    completion_enhanced = client.beta.chat.completions.parse(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_instruction},\n",
    "            {\"role\": \"user\", \"content\": enhancement_prompt}\n",
    "        ],\n",
    "        response_format=SummaryOutput,\n",
    "    )\n",
    "\n",
    "    result_enhanced = completion_enhanced.choices[0].message.parsed\n",
    "    \n",
    "    # Capture token usage manually (as done in Generation task)\n",
    "    result_enhanced.InputTokens = completion_enhanced.usage.prompt_tokens\n",
    "    result_enhanced.OutputTokens = completion_enhanced.usage.completion_tokens\n",
    "    \n",
    "    print(\"Enhanced Summary Generated.\")\n",
    "    print(result_enhanced.model_dump_json(indent=2))\n",
    "    \n",
    "    # Re-evaluate\n",
    "    test_case_enhanced = LLMTestCase(\n",
    "        input=user_prompt,\n",
    "        actual_output=result_enhanced.Summary,\n",
    "        context=[document_text]\n",
    "    )\n",
    "\n",
    "    print(\"\\nRunning evaluation on enhanced summary...\")\n",
    "    summarization_metric.measure(test_case_enhanced)\n",
    "    coherence_metric.measure(test_case_enhanced)\n",
    "    tonality_metric.measure(test_case_enhanced)\n",
    "    safety_metric.measure(test_case_enhanced)\n",
    "    \n",
    "    evaluation_output_enhanced = {\n",
    "        \"SummarizationScore\": summarization_metric.score,\n",
    "        \"SummarizationReason\": summarization_metric.reason,\n",
    "        \"CoherenceScore\": coherence_metric.score,\n",
    "        \"CoherenceReason\": coherence_metric.reason,\n",
    "        \"TonalityScore\": tonality_metric.score,\n",
    "        \"TonalityReason\": tonality_metric.reason,\n",
    "        \"SafetyScore\": safety_metric.score,\n",
    "        \"SafetyReason\": safety_metric.reason\n",
    "    }\n",
    "    \n",
    "    print(\"Enhanced Evaluation Results:\")\n",
    "    print(json.dumps(evaluation_output_enhanced, indent=2))\n",
    "    \n",
    "    # Comparison\n",
    "    print(\"\\nComparison:\")\n",
    "    print(f\"Original Summarization Score: {evaluation_output['SummarizationScore']} -> Enhanced: {evaluation_output_enhanced['SummarizationScore']}\")\n",
    "    print(f\"Original Coherence Score: {evaluation_output['CoherenceScore']} -> Enhanced: {evaluation_output_enhanced['CoherenceScore']}\")\n",
    "    print(f\"Original Tonality Score: {evaluation_output['TonalityScore']} -> Enhanced: {evaluation_output_enhanced['TonalityScore']}\")\n",
    "    print(f\"Original Safety Score: {evaluation_output['SafetyScore']} -> Enhanced: {evaluation_output_enhanced['SafetyScore']}\")\n",
    "    \n",
    "    print(\"\\nAnalysis:\")\n",
    "    if evaluation_output_enhanced['SummarizationScore'] > evaluation_output['SummarizationScore']:\n",
    "        print(\"The summary improved based on the feedback.\")\n",
    "    else:\n",
    "        print(\"The summary score did not improve significantly, possibly because the original summary was already high quality or the feedback wasn't sufficient.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error in enhancement step: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d0de25",
   "metadata": {},
   "source": [
    "Please, do not forget to add your comments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e81f47",
   "metadata": {},
   "source": [
    "\n",
    "# Submission Information\n",
    "\n",
    "ðŸš¨ **Please review our [Assignment Submission Guide](https://github.com/UofT-DSI/onboarding/blob/main/onboarding_documents/submissions.md)** ðŸš¨ for detailed instructions on how to format, branch, and submit your work. Following these guidelines is crucial for your submissions to be evaluated correctly.\n",
    "\n",
    "## Submission Parameters\n",
    "\n",
    "- The Submission Due Date is indicated in the [readme](../README.md#schedule) file.\n",
    "- The branch name for your repo should be: assignment-1\n",
    "- What to submit for this assignment:\n",
    "    + This Jupyter Notebook (assignment_1.ipynb) should be populated and should be the only change in your pull request.\n",
    "- What the pull request link should look like for this assignment: `https://github.com/<your_github_username>/production/pull/<pr_id>`\n",
    "    + Open a private window in your browser. Copy and paste the link to your pull request into the address bar. Make sure you can see your pull request properly. This helps the technical facilitator and learning support staff review your submission easily.\n",
    "\n",
    "## Checklist\n",
    "\n",
    "+ Created a branch with the correct naming convention.\n",
    "+ Ensured that the repository is public.\n",
    "+ Reviewed the PR description guidelines and adhered to them.\n",
    "+ Verify that the link is accessible in a private browser window.\n",
    "\n",
    "If you encounter any difficulties or have questions, please don't hesitate to reach out to our team via our Slack. Our Technical Facilitators and Learning Support staff are here to help you navigate any challenges.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deploying-ai-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
